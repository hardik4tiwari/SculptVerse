# SculptVerse

The Open LRM (Lightweight Reconstruction Model) for 3D reconstruction is a methodology designed to efficiently generate 3D models from 2D images, typically from multi-view datasets or single-image inputs. While various implementations of LRM approaches may differ slightly, they usually follow these key steps:

### 1. *Data Acquisition*
   - *Input*: Multiple 2D images from different viewpoints or a single image. For a complete 3D reconstruction, a set of images is ideal, with overlapping views of the object or scene.
   - *Calibration*: Camera parameters, such as focal length, distortion, and orientation, are often required for accurate 3D reconstruction. Calibration can be explicit (using known patterns) or implicit (estimated from image data).

### 2. *Feature Detection and Matching*
   - *Keypoints Extraction*: Features such as corners, edges, or textures in the images are detected using algorithms like SIFT (Scale-Invariant Feature Transform), ORB (Oriented FAST and Rotated BRIEF), or others.
   - *Feature Matching*: Corresponding points across multiple images are matched. Feature descriptors help in identifying which points in one image correspond to points in another image.

### 3. *Structure from Motion (SfM)*
   - *Camera Pose Estimation*: SfM is used to estimate the relative positions and orientations (pose) of the cameras for each image in the dataset. This is done by triangulating the matched feature points from multiple images.
   - *Sparse Point Cloud Generation*: A sparse 3D point cloud is generated by triangulating the matched points across different views.

### 4. *Multi-View Stereo (MVS)*
   - *Dense Point Cloud Generation*: MVS algorithms refine the sparse point cloud by computing a dense representation of the scene, filling in more details and producing a high-density 3D model.
   - *Surface Reconstruction*: The dense point cloud is converted into a continuous surface. This step typically uses algorithms such as Poisson surface reconstruction or Delaunay triangulation to create a mesh from the point cloud.

### 5. *Mesh Refinement*
   - *Texturing*: The reconstructed 3D surface is then textured using the original images, applying colors and textures to the surface of the 3D model to make it more visually realistic.
   - *Mesh Optimization*: Optimization techniques like simplification, smoothing, and hole-filling are applied to reduce the complexity of the mesh while preserving the important features of the model.

### 6. *Post-processing*
   - *Scaling and Alignment*: The model may be aligned with a real-world coordinate system or scaled appropriately based on known dimensions or reference points in the scene.
   - *Rendering*: Finally, the 3D model can be rendered for visualization, allowing for interaction such as rotation, zooming, or 3D printing.

## Setup

### Installation
```
git clone https://github.com//hardik4tiwari/SculptVerse.git
cd SculptVerse
```

### Environment
- Install requirements for SculptVerse first.
  ```
  pip install -r requirements.txt
  ```

## Quick Start

### Prepare Images
- We put some sample inputs under `assets/sample_input`, and you can quickly try them.
- Prepare RGBA images or RGB images with white background (with some background removal tools, e.g., [Rembg](https://github.com/danielgatis/rembg), [Clipdrop](https://clipdrop.co)).
- An example usage of preprocessing is as follows:
  ```
  #Example Usage
  IMAGE_INPUT="./assets/sample_input/box.jpg"
  IMG_PTH="INPUT/box.jpg"
  python preprocess_images.py $IMG_PTH $IMAGE_INPUT --rmbg --recenter
  ```

### Inference
- Run the inference script to get 3D assets.
- You may specify which form of output to generate by setting the flags `EXPORT_VIDEO=true` and `EXPORT_MESH=true`.
- An example usage is as follows:

  ```
  # Example usage
  EXPORT_VIDEO=true
  EXPORT_MESH=true
  INFER_CONFIG="./configs/infer-b.yaml"
  MODEL_NAME="zxhezexin/openlrm-mix-base-1.1"
  IMAGE_INPUT="./assets/sample_input/owl.png"

  python -m openlrm.launch infer.lrm --infer $INFER_CONFIG model_name=$MODEL_NAME image_input=$IMAGE_INPUT export_video=$EXPORT_VIDEO export_mesh=$EXPORT_MESH
  ```

  ### OBJ File
  - Run the conversion script to get obj model
  - An example usage is as follows:

    ```
    INPUT_FILE="path/to/input_file.ply"
    OUTPUT_FILE="path/to/output_file.obj"
    python convert_ply_to_obj.py $INPUT_FILE $OUTPUT_FILE
    ```
